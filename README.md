# üíé AnimeCut Serverless v6.0

Sistema completo de processamento de v√≠deo com IA para RunPod Serverless.

## üöÄ Funcionalidades

- ‚úÖ **AI Scene Detection** (Qwen 2.5)
- ‚úÖ **Viral Title Generation**
- ‚úÖ **Audio Transcription** (Whisper)
- ‚úÖ **GPU Rendering** (NVENC) + CPU fallback
- ‚úÖ **Backblaze B2 Integration**
- ‚úÖ **Anti-Shadowban Features**

## üì¶ Deploy no RunPod

### **1. Build da Imagem**

```bash
docker build -t animecut-serverless:v6 .
docker tag animecut-serverless:v6 seu-usuario/animecut-serverless:v6
docker push seu-usuario/animecut-serverless:v6
```

### **2. Configurar Endpoint no RunPod**

1. Acesse RunPod Console
2. Crie novo Serverless Endpoint
3. Configure:
   - **Container Image:** `seu-usuario/animecut-serverless:v6`
   - **Container Disk:** 20 GB
   - **GPU:** RTX 4090 ou A100 (recomendado)

### **3. Vari√°veis de Ambiente**

```bash
B2_KEY_ID=68702c2cbfc6
B2_APP_KEY=00506496bc1450b6722b672d9a43d00605f17eadd7
B2_ENDPOINT=https://s3.us-east-005.backblazeb2.com
B2_BUCKET_NAME=autocortes-storage
```

### **4. Volume para Modelos de IA (IMPORTANTE)**

‚ö†Ô∏è **Os modelos de IA s√£o grandes (5-10 GB) e devem ser armazenados em um Volume persistente do RunPod.**

#### **Criar Volume:**

1. No RunPod Console, v√° em **Storage** ‚Üí **Network Volumes**
2. Crie um novo volume: `animecut-models` (20 GB)
3. Monte o volume em: `/app/models`

#### **Baixar Modelos no Volume:**

Execute uma vez para popular o volume:

```python
# Qwen 2.5 (para t√≠tulos virais)
# Baixar de: https://huggingface.co/Qwen/Qwen2.5-7B-Instruct-GGUF
# Salvar em: /app/models/qwen2.5-7b-instruct-q4_k_m.gguf

# Whisper Medium (para transcri√ß√£o)
# Ser√° baixado automaticamente na primeira execu√ß√£o
```

#### **Configurar Volume no Endpoint:**

No RunPod Endpoint, adicione:
- **Volume Name:** `animecut-models`
- **Mount Path:** `/app/models`

Isso garante que os modelos sejam carregados rapidamente sem precisar baixar a cada execu√ß√£o.

## üìä Performance

| Etapa | Tempo M√©dio (GPU) |
|-------|-------------------|
| Scene Detection | 30-60s |
| Transcription | 10-20s |
| Title Generation | 5-10s |
| Rendering (NVENC) | 20-40s |
| Upload B2 | 10-30s |
| **Total** | **75-160s** |

## üîß Depend√™ncias Principais

- **llama-cpp-python** (com GGML_CUDA para GPU)
- **openai-whisper**
- **moviepy**
- **opencv-python-headless**
- **boto3** (Backblaze B2)

## üìù Notas

- O Dockerfile usa `GGML_CUDA` (n√£o `LLAMA_CUBLAS` que est√° deprecated)
- Requer GPU com CUDA 11.8+
- Modelos de IA devem estar em volume persistente
- Build time: ~15-20 minutos
- Imagem final: ~8-10 GB

## üÜò Suporte

Para problemas ou d√∫vidas, consulte a documenta√ß√£o completa no reposit√≥rio.

---

**Vers√£o:** 6.0  
**Status:** ‚úÖ Production Ready  
**√öltima atualiza√ß√£o:** 10/12/2024
